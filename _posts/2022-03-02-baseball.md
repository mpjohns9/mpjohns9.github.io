---
layout: post
title:  "Classifying Baseball Pitches by Grip Using a Convolutional Neural Network (CNN)"
subtitle: "Winter Project"
subsubtitle: "MS in Robotics &#8212 Northwestern University"
categories: [ Machine Learning, Python, ROS, Gazebo, Computer Vision ]
image: assets/images/baseball.png
gif: assets/images/baseball_compressed.gif
repo: "https://github.com/mpjohns9/MSR_Winter_Project.git"
when: January - March 2022
featured: false
hidden: false
---

A baseball pitcher places high importance on being able to deceive a hitter. The interplay between pitcher and hitter is not unlike that of two chess opponents. As such, if a hitter can detect patterns in a pitcher's behavior that tip off what pitch is being thrown, the chances of success (getting a hit) are much higher.

With this in mind, this project is the preliminary step in attempting to assess a pitcher's ability to disguise pitches. Using a convolutional neural network (CNN), baseball grips are classified with their corresponding pitch in real-time: fastball, curveball, or changeup. Combined with pose estimation, this could serve as a foundation for future development on pitch prediction in real-time.

As the following sections describe, one challenge of this project was availability to data. Since there aren't any open source datasets for baseball grip images or pitching videos from a batter's perspective, I built my own. This required a meticulous data augmentation process to generate the synthetic dataset that my model is trained and tested on.

<h5 style="font-family:montserrat">The Process</h5>   
This project can be broken down into three steps:
<ul>
    <li>Data Collection & Augmentation</li>
    <li>Training the Model</li>
    <li>Prediction in Real-Time</li>
</ul>
<img class="article-img" src="{{site.baseurl}}/assets/images/baseball-flow.png" alt="Flowchart" width="75%">

<h5 style="font-family:montserrat">Data Collection & Augmentation</h5>  
Without a readily available, open-source solution, I generated a dataset of thousands
of baseball grip images from a small subset of source images using data augmentation 
techniques such as transposition, rotation, and scaling. This allowed me to create a 
synthetic dataset large enough to train a CNN to classify pitches based on grip of 
the ball.

<h5 style="font-family:montserrat">Training the Model</h5>   
Training a convolutional neural network on my synthetic dataset resulted in ~99% accuracy when tested on data that was generated in a similar manner to the process above. That said, when tested in real life, the model demonstrated ~87% accuracy. Since most of the data collected was my own hand, I expected some overfitting to be present. I plan to address this moving forward by diversifying my dataset.
<figure>
<img class="article-img" src="{{site.baseurl}}/assets/images/baseball-network.png" alt="Flowchart" width="75%">
<figcaption class="image-caption">CNN architecture used for this project. <br>Note: Image generated by author using template from https://github.com/kennethleungty/Neural-Network-Architecture-Diagrams.</figcaption>
</figure>

<h5 style="font-family:montserrat">Prediction in Real-Time</h5>  
This step can be seen in the video above. The classifier trained in the previous step
is running on real-time video data. Frames are classified based on the grip a user offers to the camera, then an averaging algorithm displays the result on screen in blue text. 

<h5 style="font-family:montserrat">Next Steps</h5>  
The ultimate goal of this project is to provide pitchers feedback on how well they are 
disguising their pitches. In the short-term, I will implement an object detection algorithm 
I developed for still images on the same video stream you see here. After that, I plan 
to generate an additional data set with actual pitches from a hitter's perspective. With 
this, I plan to add pitching mechanics (via pose estimation) to the model.

<a class="repo-link" href="{{post.repo}}" target="_blank" rel="noopener noreferrer">Github Repository</a>

